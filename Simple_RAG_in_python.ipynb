{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JqDfwMd1dNnTkBJZJsgnspFN7llgVGtv",
      "authorship_tag": "ABX9TyOcOe+oAFy9a6sc+xZYnJwJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary packages\n",
        "we will use langchain and and google generative ai sdk"
      ],
      "metadata": {
        "id": "U8VnbbobSRZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhPAPEGKEVQF"
      },
      "outputs": [],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install langchain-google-genai --quiet\n",
        "!pip install --upgrade --quiet  langchain-core langchain-community\n",
        "!pip install --upgrade langchain --quiet\n",
        "!pip install -U langchain-text-splitters --quiet\n",
        "!pip install pypdf --quiet\n",
        "# Assuming an embedding model is also set up via LangChain or another library"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai==0.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PNjFJ_gMyiB",
        "outputId": "fe29b6ec-9e31-4950-95db-6d861326bd71"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/163.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/163.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/717.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/717.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.3/717.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### add your google ai api key in the secrets in colab"
      ],
      "metadata": {
        "id": "lvABWyMGSdJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "8V9SVui0M_mM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# for embedding model\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "ha1pWPtpNJ3v"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# for llm\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "Q8_mfE9IXzKq"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load PDF and generate embeddings"
      ],
      "metadata": {
        "id": "x3JwTVz_FetZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import format_document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import (\n",
        "    ChatGoogleGenerativeAI,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        ")"
      ],
      "metadata": {
        "id": "Z0LEhr5IZBl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Capstone Project/dataviz_1.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "# Split text into manageable chunks\n",
        "text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=100)\n",
        "document_chunks = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "PFEA_1r7EZY5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the page content of first chunks"
      ],
      "metadata": {
        "id": "syLmYM04Sox2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks[20].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nYzIVpVyJHOn",
        "outputId": "e5164751-3e21-40ad-d280-ac055337acba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Length\\n20Incorrect bar graph on left \\nand correct one on the right . \\nThe chart on the right shows the \\nchange when the axis starts at \\nzero, which looks less dramatic \\nfor differences.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test the embedding algorithm"
      ],
      "metadata": {
        "id": "dr1XQvZiSv2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "result = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\")\n",
        "\n",
        "# 1 input > 1 vector output\n",
        "print(str(result['embedding'])[:50], '... TRIMMED]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OeFqv0yMJzLN",
        "outputId": "09b88384-899d-47b3-bcdc-58f6a8756a25"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.003216741, -0.013358698, -0.017649598, -0.0091 ... TRIMMED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyYV2mN4NUaJ",
        "outputId": "de59ba2e-29bf-4602-e1aa-b0c0cf70bfc7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### retrieve the embeddings of the pdf contents, chunk to chunk"
      ],
      "metadata": {
        "id": "KhEfbf9oS2aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings\n",
        "def generate_embeddings(text_chunks):\n",
        "    return genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=text_chunks,\n",
        "    task_type=\"retrieval_document\")['embedding']\n",
        "\n",
        "embeddings = generate_embeddings([chunk.page_content for chunk in document_chunks])"
      ],
      "metadata": {
        "id": "8iierLDeJFfa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"total dim of embeddings from the whoe pdf (len of chunks, 768 vectors)\")\n",
        "len(embeddings), len(embeddings[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGc691sIFuoJ",
        "outputId": "64795e6b-1388-4eaa-aca6-acf47c631042"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dim of embeddings from the whoe pdf (len of chunks, 768 vectors)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to retrieve relevant sections\n",
        "\n",
        "use **cosine similarity to retrive the top n similar chunks** from the pdf based on the query"
      ],
      "metadata": {
        "id": "sH__Z02JFaR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def retrieve_relevant_sections(query, embeddings, chunks, top_k=3):\n",
        "    query_embedding = generate_embeddings([query])[0]  # Assuming single query\n",
        "    scores = cosine_similarity([query_embedding], embeddings)[0]\n",
        "    top_indices = np.argsort(scores)[-top_k:]\n",
        "    return [chunks[i] for i in top_indices]\n"
      ],
      "metadata": {
        "id": "elX8w12UE5FO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invoke the pipeline on a sample query"
      ],
      "metadata": {
        "id": "48XKmdwTFpvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample query\n",
        "query = \"Describe the main visualization techniques used in the data.\"\n",
        "\n",
        "# Retrieve relevant sections\n",
        "relevant_sections = retrieve_relevant_sections(query, embeddings, [chunk.page_content for chunk in document_chunks], top_k=5)"
      ],
      "metadata": {
        "id": "Y5ehUFAEFXaL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, rs in enumerate(relevant_sections):\n",
        "  print(\"Relevant section\", i)\n",
        "  print(rs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AMP3Y8OF72v",
        "outputId": "3b17efb4-724a-413e-c975-40ad75cf97e3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant section 0\n",
            "Boxplot on a\n",
            "normal \n",
            "distribution\n",
            "50Credit: https ://towardsdatascience.com/\n",
            "Relevant section 1\n",
            "Symbol plots\n",
            "41\n",
            "Relevant section 2\n",
            "Boxplot\n",
            "48\n",
            "Credit: https ://towardsdatascience.com/Fence\n",
            "Relevant section 3\n",
            "Boxplot –\n",
            "Notations\n",
            "49Credit: https ://towardsdatascience.com/\n",
            "Relevant section 4\n",
            "33\n",
            "Viewed separately, the visualization \n",
            "components aren’t that useful because \n",
            "they are just bits of geometry floating in \n",
            "an empty space without context. \n",
            "However, when we put the components \n",
            "togethe r, you get a complete visualization \n",
            "worth looking at.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup LLM and create prompt"
      ],
      "metadata": {
        "id": "MuOb49afFm62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "list the available gemini models"
      ],
      "metadata": {
        "id": "nGwSVUijdDMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "jRBB86ICVIhz",
        "outputId": "4c9105b1-5ea3-42ea-9fcb-40fbcc709d49"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we'll use the latest gemini-1.5-pro"
      ],
      "metadata": {
        "id": "paL7ZvAcdJTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\",\n",
        "                             safety_settings={\n",
        "                                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "                                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
        "                                # HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                                }, temperature=0.7, top_p=0.85)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Analyze the content following: {text} and answer the question: {question} \\\n",
        "                                            give the output in json format: {{'output': <output>\\}}\")"
      ],
      "metadata": {
        "id": "mNhdGuwAE6-2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build a llm chain and invoke the prompts"
      ],
      "metadata": {
        "id": "hZ_FQsZ8dOP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = (\n",
        "              # Extract data from documents and add to the key \"text\"\n",
        "              {\n",
        "                \"text\": lambda content: \"\\n\\n\".join(s for s in content),\n",
        "                \"question\": lambda question: question\n",
        "                }\n",
        "              # Prompt for Gemini\n",
        "              | prompt\n",
        "              # Gemini function\n",
        "              | llm\n",
        "              # Output parser\n",
        "              | StrOutputParser()\n",
        "            )"
      ],
      "metadata": {
        "id": "GvmqP8fZI0u_"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output"
      ],
      "metadata": {
        "id": "BerWW78MdrFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm_chain.invoke({\"text\": relevant_sections, \"question\": query})"
      ],
      "metadata": {
        "id": "97OmyWXbdXw8"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json_output(response):\n",
        "    response = response.strip(\"`json JSON\").replace('\\n','').replace('\\t','')\n",
        "    return json.loads(response)"
      ],
      "metadata": {
        "id": "bDjC2keldypy"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_json_output(output)['output']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "KIrnZlvye37U",
        "outputId": "8fbb8709-0624-4388-e8a0-20e78597751e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The provided text mentions several visualization techniques, primarily focusing on **boxplots**:* **Boxplot:** This is the central visualization method highlighted, emphasized by its repetition and detailed breakdown across different text segments. * **Symbol plots:** While briefly mentioned, the exact nature of these plots isn't detailed. They could represent various things like scatter plots, dot plots, etc., depending on the data and context.* **Notations:** This refers to the use of labels, titles, axis descriptions, and other textual elements within the visualizations to provide context and clarity.**The text emphasizes the importance of combining these elements.** Individual components like boxes, whiskers, or symbols are less meaningful in isolation.  A complete visualization combines these techniques to represent data distribution, outliers, and central tendencies effectively. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    }
  ]
}